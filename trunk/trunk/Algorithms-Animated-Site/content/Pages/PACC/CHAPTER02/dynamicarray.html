<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html401/sgml/dtd.html">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
<script language="JavaScript">nestingDepth = "../../../../";</script>
<script language="JavaScript" src="../../../noteConstants.js"></script>
<script language="JavaScript" src="../../../../webWriter/buttonClass.js"></script>
<script language="JavaScript" src="../../../../webWriter/parser.js"></script>
<script language="JavaScript" src="../../../../webWriter/web_writer.js"></script>
<script type="text/x-mathjax-config">MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<title>Dynamic arrays</title>
<link href="../../../../style/lectureScreen.css" rel="stylesheet" type="text/css"/>
</head>
<body>
    
<p>
If we want to use an array in order to implement a dynamic linear sequence,
it is necessary to make some modifications that allow us to execute a
redimensioning of the array (several modern languages, such as C++, C#, and Java
include arrays whose dimension can vary over time). We will consider the
insertion and the deletion at the end of an array $a$ of $n$ elements in order
to illustrate the management of the redimensioning. Allocating a new array
(greater or smaller) in order to copy the elements of $a$ at each change of its
dimension may require $O(n)$ time for each operation: this can turn out to be
too expensive from a computational point of view (even if it is optimal in terms
of used memory). By means of some small tricks, however, we can pay time $O(n)$
for each group of $\Omega(n)$ operations: that is, we obtain a distributed
constant cost for each operation.
</p>

<p>
Let $d$ be the number of elements of the array $a$ currently allocated in
the memory and let $n \leq d$ be the number of elements actually contained in
the sequence stored in $a$. Every time an insert operation is performed, if
there is sufficient space (that is, $n+1 \leq d$), we increase $n$ by one.
Otherwise, if $n=d$, then we allocate an array $b$ of size $2d$, we double $d$,
we copy the $n$ eleements of $s$ into $b$ and we set $a=b$. Analogously, every
time a delete operation is executed, we decrease $n$ by one. When $n=d/4$, we
half the array $a$: we allocate an array $b$ of size $d/2$, we half $d$, and we
copy the $n$ elements of $a$ in $b$ by setting $a=b$. This operations are shown
in the following code.
</p>

<p>
<script language="JavaScript">
setButtons(true, false, true,"","");
setSourceRoot( "../../../src/" ) ;
insertCode("pacc/chapter02/DynamicArray.java", true, "code", "dynamicarray.tmcfg", "ww", "tm&!S");
</script>
</p>

<h2>Complexity analysis</h2>
<p>
In order to compute the time complexity of a group of operations, we make use of a typical analysis technique for the evaluation of the <em>amortized analysis</em> of a data structure, that is, the <b>potential function</b> technique. Intuitively, in the case of the dynamic arrays the potential function indicates the energy accumulated at each insertion/deletion and released at each expansion/contraction: in particular, this function is equal to 0 after each expansion/contraction and increases at each insertion/deletion. Let $d_j$ and $n_j$ be the value of $d$ and $n$ after the execution of the $j$-th operation. We then define \[
\Phi(j) = \left\{\begin{array}{ll}
2n_j-d_j & \mbox{if $n(j)\geq\frac{d_j}{2}$}\\
\frac{d_j}{2}-n_j & \mbox{otherwise}
\end{array}\right.
\]
Note that if $n_j$ and $d_j$ are both equal to 0, then $\Phi(j)=0$: this implies that at the beginning the potential function is equal to 0. Moreover, it follows from the definition that $\Phi(j) \geq 0$ for any $j$.
</p>

<h3>Amortized cost of an insertion</h3>
<p>
Let us distinguish the following two cases.
</p>
<ol style="list-style-type: decimal;">
<li>$n_{j-1}\geq\frac{d_{j-1}}{2}$. In this case, if the $j$-th operation does not cause an expansion, then $d_j=d_{j-1}$ and $n_j=n_{j-1}+1$. This implies that the amortized cost of the operation is equal to \[\hat{c}_j = c_j+\Phi(j)-\Phi(j-1) = 1+2n_j-d_j-2(n_j-1)-d_j = 3,\]where $c_j=1$ is the cost of executing the insertion. Otherwise (that is, if the $j$-th operation causes an expansion) $d_j=2d_{j-1}$ and $n_j=n_{j-1}+1=d_{j-1}+1$. This implies that the amortized cost of the operation is equal to \begin{eqnarray*}
\hat{c}_j & = & c_j+\Phi(j)-\Phi(j-1) = n_j+(2n_j-d_j)-(2n_{j-1}-d_{j-1})\\
& = & n_j+(2n_j-2(n_j-1))-(2(n_j-1)-(n_j-1))\\
& = & n_j+2-n_j+1 = 3,
\end{eqnarray*}
where $c_j=n_j$ is the cost of executing the insertion and the expansion.</li>
<li>$n_{j-1}<\frac{d_{j-1}}{2}$. In this case, the $j$-th operation certainly does not cause an expansion. If $n_j < \frac{d_j}{2}$, then \[\hat{c}_j = c_j+\Phi(j)-\Phi(j-1) = 1+\frac{d_j}{2}-n_j-\left(\frac{d_j}{2}-(n_j-1)\right) = 0.\]Otherwise (that is, $n_j \geq \frac{d_j}{2}$)\begin{eqnarray*}
\hat{c}_j & = & c_j+\Phi(j)-\Phi(j-1) = 1+(2n_j-d_j)-\left(\frac{d_j}{2}-n_{j-1}\right)\\
& = & 1+(2(n_{j-1}+1)-d_{j-1})-\left(\frac{d_j}{2}-n_{j-1}\right)\\
& = & 3n_{j-1}-\frac{3}{2}d_{j-1}+3 < \frac{3}{2}d_{j-1}-\frac{3}{2}d_{j-1}+3 = 3
\end{eqnarray*}
</li>
</ol>
<p>
In both cases, the amortized cost is bounded by a constant (that is, 3).
</p>

<h3>Amortized cost of a deletion</h3>
<p>
Analogously to the anlysis of an insertion, we can prove that the amortized cost of this operation is also bounded by a constant.
</p>

<h3>Cost of a sequence of operations</h3>
<p>
Let $\sigma$ be a sequence of operations and let $cost(\sigma)$ denote the cost of the execution of all the operations in the sequence. Since the potential function is 0 at the beginning and at least 0 at the end and because of the previous analysis, we have that \[cost(\sigma) \leq \sum_{j=0}^{n-1}\hat{c_j} \leq \alpha\sum_{j=1}^{n}1 = \alpha n,\]where $\alpha$ is a constant.
</p>

<p>
<script language="JavaScript">
bottomStamp(true, true);
</script>
</p>
</body>
</html>